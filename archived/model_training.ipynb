{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-20T17:21:13.837044Z",
     "iopub.status.busy": "2025-11-20T17:21:13.836828Z",
     "iopub.status.idle": "2025-11-20T17:21:25.123590Z",
     "shell.execute_reply": "2025-11-20T17:21:25.123309Z"
    },
    "id": "wP3kZtOKZQmr",
    "outputId": "cd1b50c6-b8c1-46fc-d38b-ed27b98dd042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get rows 0 - 999 ...\n",
      "Progress：1000/40000 (2.5%)\n",
      "Get rows 1000 - 1999 ...\n",
      "Progress：2000/40000 (5.0%)\n",
      "Get rows 2000 - 2999 ...\n",
      "Progress：3000/40000 (7.5%)\n",
      "Get rows 3000 - 3999 ...\n",
      "Progress：4000/40000 (10.0%)\n",
      "Get rows 4000 - 4999 ...\n",
      "Progress：5000/40000 (12.5%)\n",
      "Get rows 5000 - 5999 ...\n",
      "Progress：6000/40000 (15.0%)\n",
      "Get rows 6000 - 6999 ...\n",
      "Progress：7000/40000 (17.5%)\n",
      "Get rows 7000 - 7999 ...\n",
      "Progress：8000/40000 (20.0%)\n",
      "Get rows 8000 - 8999 ...\n",
      "Progress：9000/40000 (22.5%)\n",
      "Get rows 9000 - 9999 ...\n",
      "Progress：10000/40000 (25.0%)\n",
      "Get rows 10000 - 10999 ...\n",
      "Progress：11000/40000 (27.5%)\n",
      "Get rows 11000 - 11999 ...\n",
      "Progress：12000/40000 (30.0%)\n",
      "Get rows 12000 - 12999 ...\n",
      "Progress：13000/40000 (32.5%)\n",
      "Get rows 13000 - 13999 ...\n",
      "Progress：14000/40000 (35.0%)\n",
      "Get rows 14000 - 14999 ...\n",
      "Progress：15000/40000 (37.5%)\n",
      "Get rows 15000 - 15999 ...\n",
      "Progress：16000/40000 (40.0%)\n",
      "Get rows 16000 - 16999 ...\n",
      "Progress：17000/40000 (42.5%)\n",
      "Get rows 17000 - 17999 ...\n",
      "Progress：18000/40000 (45.0%)\n",
      "Get rows 18000 - 18999 ...\n",
      "Progress：19000/40000 (47.5%)\n",
      "Get rows 19000 - 19999 ...\n",
      "Progress：20000/40000 (50.0%)\n",
      "Get rows 20000 - 20999 ...\n",
      "Progress：21000/40000 (52.5%)\n",
      "Get rows 21000 - 21999 ...\n",
      "Progress：22000/40000 (55.0%)\n",
      "Get rows 22000 - 22999 ...\n",
      "Progress：23000/40000 (57.5%)\n",
      "Get rows 23000 - 23999 ...\n",
      "Progress：24000/40000 (60.0%)\n",
      "Get rows 24000 - 24999 ...\n",
      "Progress：25000/40000 (62.5%)\n",
      "Get rows 25000 - 25999 ...\n",
      "Progress：26000/40000 (65.0%)\n",
      "Get rows 26000 - 26999 ...\n",
      "Progress：27000/40000 (67.5%)\n",
      "Get rows 27000 - 27999 ...\n",
      "Progress：28000/40000 (70.0%)\n",
      "Get rows 28000 - 28999 ...\n",
      "Progress：29000/40000 (72.5%)\n",
      "Get rows 29000 - 29999 ...\n",
      "Progress：30000/40000 (75.0%)\n",
      "Get rows 30000 - 30999 ...\n",
      "Progress：31000/40000 (77.5%)\n",
      "Get rows 31000 - 31999 ...\n",
      "Progress：32000/40000 (80.0%)\n",
      "Get rows 32000 - 32999 ...\n",
      "Progress：33000/40000 (82.5%)\n",
      "Get rows 33000 - 33999 ...\n",
      "Progress：34000/40000 (85.0%)\n",
      "Get rows 34000 - 34999 ...\n",
      "Progress：35000/40000 (87.5%)\n",
      "Get rows 35000 - 35999 ...\n",
      "Progress：36000/40000 (90.0%)\n",
      "Get rows 36000 - 36999 ...\n",
      "Progress：37000/40000 (92.5%)\n",
      "Get rows 37000 - 37999 ...\n",
      "Progress：38000/40000 (95.0%)\n",
      "Get rows 38000 - 38999 ...\n",
      "Progress：39000/40000 (97.5%)\n",
      "Get rows 39000 - 39999 ...\n",
      "Progress：40000/40000 (100.0%)\n",
      "Raw file saved： freddie_mac_delinquency_balanced.csv\n",
      "Total rows： 40000\n",
      "Headings count： 52\n",
      "Headings： ['loan_identifier', 'period', 'period_year', 'period_month', 'amortization_type', 'seller_name', 'property_state', 'msa', 'first_payment_date', 'maturity_date', 'original_loan_term', 'original_interest_rate', 'original_upb', 'loan_purpose', 'channel', 'property_type', 'number_of_units', 'occupancy_status', 'first_time_homebuyer_indicator', 'credit_score', 'original_loan_to_value_ltv', 'original_debt_to_income_dti_ratio', 'mortgage_insurance_percentage_mi_percent', 'loan_age', 'remaining_months_to_legal_maturity', 'current_loan_delinquency_status', 'payment_history', 'current_interest_rate', 'current_actual_upb', 'modification_flag', 'delinquency_due_to_disaster', 'bankruptcy_flag', 'number_of_modifications', 'modification_debt_to_income_ratio', 'interest_rate_step_indicator', 'property_valuation_method', 'borrower_assistance_plan', 'payment_deferral_flag', 'distressed_principal_balance_flag', 'delinquency_30d_label', 'loan_to_value_ratio_bucket', 'loan_age_years', 'interest_rate_diff', 'high_dti_flag', 'credit_score_bucket', 'recent_delinquency_flag', 'state_default_rate', 'msa_default_rate', 'loan_size_bucket', 'interest_rate_bucket', 'seasonality_flag', 'modification_history_flag']\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 0: 从 Supabase 获取数据\n",
    "# =============================================\n",
    "# !pip install supabase pandas scikit-learn\n",
    "\n",
    "from supabase import create_client, Client\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "url = \"https://ptukzshzuloxipzwycte.supabase.co\"\n",
    "key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB0dWt6c2h6dWxveGlwend5Y3RlIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTIxNjg0OTMsImV4cCI6MjA2Nzc0NDQ5M30.MAnlnrt0traaFjE-QV3jSKETU6woZJ8LcVIqjrAIiQ4\"\n",
    "supabase: Client = create_client(url, key)\n",
    "\n",
    "table_name = \"freddie_mac_delinquency_30_model_2013_2025\"\n",
    "rows = []\n",
    "batch_size = 1000\n",
    "offset = 0\n",
    "max_rows = 40000\n",
    "\n",
    "while offset < max_rows:\n",
    "    print(f\"Get rows {offset} - {offset + batch_size - 1} ...\")\n",
    "    try:\n",
    "        res = supabase.table(table_name).select(\"*\").range(offset, offset + batch_size - 1).execute()\n",
    "        if not res.data:\n",
    "            print(\"End data reading.\")\n",
    "            break\n",
    "        rows.extend(res.data)\n",
    "        offset += batch_size\n",
    "        print(f\"Progress：{offset}/{max_rows} ({(offset/max_rows)*100:.1f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request fail：{e}，retry after 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "csv_name = \"freddie_mac_delinquency_balanced.csv\"\n",
    "df.to_csv(csv_name, index=False)\n",
    "print(\"Raw file saved：\", csv_name)\n",
    "print(\"Total rows：\", df.shape[0])\n",
    "print(\"Headings count：\", df.shape[1])\n",
    "print(\"Headings：\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "数据时间分布\n",
      "============================================================\n",
      "period_year\n",
      "2013    1140\n",
      "2014    2729\n",
      "2015    5361\n",
      "2016    2422\n",
      "2017    3585\n",
      "2018    3223\n",
      "2019    3729\n",
      "2020    2425\n",
      "2021    3501\n",
      "2022    2655\n",
      "2023    1101\n",
      "2024    4540\n",
      "2025    3589\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "步骤 1: 按全局时间划分\n",
      "============================================================\n",
      "训练集年份: [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
      "验证集年份: [2022, 2023]\n",
      "测试集年份: [2024, 2025]\n",
      "\n",
      "初步划分结果:\n",
      "训练集: 28,115 条记录\n",
      "验证集: 3,756 条记录\n",
      "测试集: 8,129 条记录\n",
      "\n",
      "============================================================\n",
      "步骤 2: Loan ID 隔离\n",
      "============================================================\n",
      "训练集 Loan 数量: 25,643\n",
      "验证集 Loan 数量: 3,609\n",
      "测试集 Loan 数量: 7,872\n",
      "\n",
      "重叠情况:\n",
      "训练集与验证集重叠 Loan: 49\n",
      "训练集与测试集重叠 Loan: 0\n",
      "验证集与测试集重叠 Loan: 59\n",
      "\n",
      "隔离后:\n",
      "测试集 Loan 数量: 7,813\n",
      "\n",
      "============================================================\n",
      "步骤 3: 最终数据集统计\n",
      "============================================================\n",
      "训练集: 28,115 条记录, 25,643 个 loan\n",
      "验证集: 3,756 条记录, 3,609 个 loan\n",
      "测试集: 8,066 条记录, 7,813 个 loan\n",
      "\n",
      "============================================================\n",
      "步骤 4: 类别分布检查\n",
      "============================================================\n",
      "训练集 - 违约比例: 0.5013 (14,095 / 28,115)\n",
      "验证集 - 违约比例: 0.4712 (1,770 / 3,756)\n",
      "测试集 - 违约比例: 0.5055 (4,077 / 8,066)\n",
      "\n",
      "训练集不平衡比例: 0.99:1 (正常:违约)\n",
      "\n",
      "============================================================\n",
      "步骤 5: 数据隔离验证\n",
      "============================================================\n",
      "训练集与测试集 Loan 重叠: 0 (应该 = 0)\n",
      "验证集与测试集 Loan 重叠: 0 (应该 = 0)\n",
      "\n",
      "✅ 数据隔离验证通过！\n",
      "\n",
      "============================================================\n",
      "步骤 6: 时间范围检查\n",
      "============================================================\n",
      "训练集时间范围: 201307 - 202112\n",
      "验证集时间范围: 202201 - 202312\n",
      "测试集时间范围: 202401 - 202506\n",
      "\n",
      "============================================================\n",
      "时间外推验证说明\n",
      "============================================================\n",
      "\n",
      "✓ 训练集 (2013-2021): 用于训练模型\n",
      "✓ 验证集 (2022-2023): 用于调参和概率校准\n",
      "✓ 测试集 (2024-2025): 用于最终评估（真正的时间外推）\n",
      "\n",
      "评估维度:\n",
      "1. 验证集性能 → 模型对\"近期数据\"的预测能力\n",
      "2. 测试集性能 → 模型对\"未来新客户\"的预测能力（最重要！）\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 1: 全局时间划分 + Loan ID 隔离\n",
    "# =============================================\n",
    "# 修正后的方案：\n",
    "# 1. 按全局时间划分（不是按每个 loan 内部划分）\n",
    "# 2. 训练集: 2013-2021，验证集: 2022-2023，测试集: 2024-2025\n",
    "# 3. 测试集的 loan 不能出现在训练集/验证集中（避免数据泄漏）\n",
    "# 4. 同一个 loan 的所有记录保持在一起\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 确保必要的列存在\n",
    "assert 'loan_identifier' in df.columns, \"loan_identifier 列不存在！\"\n",
    "assert 'period' in df.columns, \"period 列不存在！\"\n",
    "\n",
    "target_col = \"delinquency_30d_label\"\n",
    "assert target_col in df.columns, f\"{target_col} 列不存在！\"\n",
    "\n",
    "# 转换 period 为字符串格式，并提取年份\n",
    "df['period'] = df['period'].astype(str)\n",
    "df['period_year'] = df['period'].str[:4].astype(int)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"数据时间分布\")\n",
    "print(\"=\" * 60)\n",
    "print(df['period_year'].value_counts().sort_index())\n",
    "\n",
    "# =============================================\n",
    "# 步骤 1: 按全局时间划分\n",
    "# =============================================\n",
    "# 训练集: 2013-2021 (用于训练模型)\n",
    "# 验证集: 2022-2023 (用于调参和概率校准)\n",
    "# 测试集: 2024-2025 (用于最终评估 - 真正的时间外推)\n",
    "\n",
    "train_years = list(range(2013, 2022))  # 2013-2021\n",
    "val_years = [2022, 2023]               # 2022-2023\n",
    "test_years = [2024, 2025]              # 2024-2025\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"步骤 1: 按全局时间划分\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"训练集年份: {train_years}\")\n",
    "print(f\"验证集年份: {val_years}\")\n",
    "print(f\"测试集年份: {test_years}\")\n",
    "\n",
    "# 初步按时间划分\n",
    "df_train_raw = df[df['period_year'].isin(train_years)].copy()\n",
    "df_val_raw = df[df['period_year'].isin(val_years)].copy()\n",
    "df_test_raw = df[df['period_year'].isin(test_years)].copy()\n",
    "\n",
    "print(f\"\\n初步划分结果:\")\n",
    "print(f\"训练集: {len(df_train_raw):,} 条记录\")\n",
    "print(f\"验证集: {len(df_val_raw):,} 条记录\")\n",
    "print(f\"测试集: {len(df_test_raw):,} 条记录\")\n",
    "\n",
    "# =============================================\n",
    "# 步骤 2: Loan ID 隔离（避免数据泄漏）\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"步骤 2: Loan ID 隔离\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 找出各时间段的 loan\n",
    "train_loans = set(df_train_raw['loan_identifier'].unique())\n",
    "val_loans = set(df_val_raw['loan_identifier'].unique())\n",
    "test_loans_raw = set(df_test_raw['loan_identifier'].unique())\n",
    "\n",
    "print(f\"训练集 Loan 数量: {len(train_loans):,}\")\n",
    "print(f\"验证集 Loan 数量: {len(val_loans):,}\")\n",
    "print(f\"测试集 Loan 数量: {len(test_loans_raw):,}\")\n",
    "\n",
    "# 检查重叠\n",
    "train_val_overlap = train_loans & val_loans\n",
    "train_test_overlap = train_loans & test_loans_raw\n",
    "val_test_overlap = val_loans & test_loans_raw\n",
    "\n",
    "print(f\"\\n重叠情况:\")\n",
    "print(f\"训练集与验证集重叠 Loan: {len(train_val_overlap):,}\")\n",
    "print(f\"训练集与测试集重叠 Loan: {len(train_test_overlap):,}\")\n",
    "print(f\"验证集与测试集重叠 Loan: {len(val_test_overlap):,}\")\n",
    "\n",
    "# 从测试集中移除在训练集/验证集中出现过的 loan\n",
    "contaminated_loans = train_loans | val_loans\n",
    "df_test = df_test_raw[~df_test_raw['loan_identifier'].isin(contaminated_loans)].copy()\n",
    "\n",
    "df_val = df_val_raw.copy()\n",
    "df_train = df_train_raw.copy()\n",
    "\n",
    "print(f\"\\n隔离后:\")\n",
    "print(f\"测试集 Loan 数量: {df_test['loan_identifier'].nunique():,}\")\n",
    "\n",
    "# =============================================\n",
    "# 步骤 3: 最终数据集统计\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"步骤 3: 最终数据集统计\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"训练集: {len(df_train):,} 条记录, {df_train['loan_identifier'].nunique():,} 个 loan\")\n",
    "print(f\"验证集: {len(df_val):,} 条记录, {df_val['loan_identifier'].nunique():,} 个 loan\")\n",
    "print(f\"测试集: {len(df_test):,} 条记录, {df_test['loan_identifier'].nunique():,} 个 loan\")\n",
    "\n",
    "# =============================================\n",
    "# 步骤 4: 类别分布检查\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"步骤 4: 类别分布检查\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_pos_rate = df_train[target_col].mean()\n",
    "val_pos_rate = df_val[target_col].mean()\n",
    "test_pos_rate = df_test[target_col].mean() if len(df_test) > 0 else 0\n",
    "\n",
    "print(f\"训练集 - 违约比例: {train_pos_rate:.4f} ({df_train[target_col].sum():,} / {len(df_train):,})\")\n",
    "print(f\"验证集 - 违约比例: {val_pos_rate:.4f} ({df_val[target_col].sum():,} / {len(df_val):,})\")\n",
    "print(f\"测试集 - 违约比例: {test_pos_rate:.4f} ({df_test[target_col].sum():,} / {len(df_test):,})\")\n",
    "\n",
    "train_imbalance = (1 - train_pos_rate) / train_pos_rate if train_pos_rate > 0 else float('inf')\n",
    "print(f\"\\n训练集不平衡比例: {train_imbalance:.2f}:1 (正常:违约)\")\n",
    "\n",
    "# =============================================\n",
    "# 步骤 5: 数据隔离验证\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"步骤 5: 数据隔离验证\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_train_loans = set(df_train['loan_identifier'].unique())\n",
    "final_val_loans = set(df_val['loan_identifier'].unique())\n",
    "final_test_loans = set(df_test['loan_identifier'].unique()) if len(df_test) > 0 else set()\n",
    "\n",
    "train_test_final = len(final_train_loans & final_test_loans)\n",
    "val_test_final = len(final_val_loans & final_test_loans)\n",
    "\n",
    "print(f\"训练集与测试集 Loan 重叠: {train_test_final} (应该 = 0)\")\n",
    "print(f\"验证集与测试集 Loan 重叠: {val_test_final} (应该 = 0)\")\n",
    "\n",
    "if train_test_final == 0 and val_test_final == 0:\n",
    "    print(\"\\n✅ 数据隔离验证通过！\")\n",
    "else:\n",
    "    print(\"\\n❌ 警告：存在数据泄漏！\")\n",
    "\n",
    "# =============================================\n",
    "# 步骤 6: 时间范围检查\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"步骤 6: 时间范围检查\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"训练集时间范围: {df_train['period'].min()} - {df_train['period'].max()}\")\n",
    "print(f\"验证集时间范围: {df_val['period'].min()} - {df_val['period'].max()}\")\n",
    "if len(df_test) > 0:\n",
    "    print(f\"测试集时间范围: {df_test['period'].min()} - {df_test['period'].max()}\")\n",
    "else:\n",
    "    print(\"测试集: 无数据（所有 loan 都在训练/验证集中出现过）\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"时间外推验证说明\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "✓ 训练集 (2013-2021): 用于训练模型\n",
    "✓ 验证集 (2022-2023): 用于调参和概率校准\n",
    "✓ 测试集 (2024-2025): 用于最终评估（真正的时间外推）\n",
    "\n",
    "评估维度:\n",
    "1. 验证集性能 → 模型对\"近期数据\"的预测能力\n",
    "2. 测试集性能 → 模型对\"未来新客户\"的预测能力（最重要！）\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 清洗后: (28115, 39)\n",
      "验证集 清洗后: (3756, 39)\n",
      "测试集 清洗后: (8066, 39)\n",
      "\n",
      "==================================================\n",
      "基于训练集确定特征选择\n",
      "==================================================\n",
      "高缺失率列 (>40%): ['modification_flag', 'delinquency_due_to_disaster', 'bankruptcy_flag', 'number_of_modifications', 'modification_debt_to_income_ratio', 'interest_rate_step_indicator', 'property_valuation_method', 'borrower_assistance_plan', 'payment_deferral_flag', 'state_default_rate', 'msa_default_rate', 'modification_history_flag']\n",
      "低方差列: ['number_of_modifications', 'state_default_rate', 'msa_default_rate', 'modification_history_flag']\n",
      "高相关列 (>0.9): []\n",
      "\n",
      "总共删除列数: 12\n",
      "训练集 删除后: (28115, 27)\n",
      "验证集 删除后: (3756, 27)\n",
      "测试集 删除后: (8066, 27)\n",
      "\n",
      "==================================================\n",
      "LabelEncoder 编码（只用训练集 fit）\n",
      "==================================================\n",
      "需要编码的列: ['amortization_type', 'seller_name', 'property_state', 'loan_purpose', 'channel', 'property_type', 'occupancy_status', 'first_time_homebuyer_indicator', 'distressed_principal_balance_flag']\n",
      "编码完成，共 9 个编码器\n",
      "\n",
      "==================================================\n",
      "缺失值填充（用训练集统计量）\n",
      "==================================================\n",
      "训练集 填充后缺失值: 0\n",
      "验证集 填充后缺失值: 0\n",
      "测试集 填充后缺失值: 0\n",
      "\n",
      "==================================================\n",
      "最终数据集\n",
      "==================================================\n",
      "训练集: (28115, 25)\n",
      "验证集: (3756, 25)\n",
      "测试集: (8066, 25)\n",
      "\n",
      "特征列: ['period_month', 'amortization_type', 'seller_name', 'property_state', 'msa', 'original_loan_term', 'original_interest_rate', 'original_upb', 'loan_purpose', 'channel', 'property_type', 'number_of_units', 'occupancy_status', 'first_time_homebuyer_indicator', 'credit_score', 'original_loan_to_value_ltv', 'original_debt_to_income_dti_ratio', 'mortgage_insurance_percentage_mi_percent', 'current_interest_rate', 'current_actual_upb', 'distressed_principal_balance_flag', 'loan_age_years', 'interest_rate_diff', 'recent_delinquency_flag']\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 2: 数据清洗和特征工程（分别处理三个数据集）\n",
    "# =============================================\n",
    "# 原则：\n",
    "# 1. 清洗逻辑对三个数据集分别应用\n",
    "# 2. LabelEncoder 只用训练集 fit，验证/测试集只 transform\n",
    "# 3. 缺失值填充用训练集的统计量\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "target_col = \"delinquency_30d_label\"\n",
    "\n",
    "# =============================================\n",
    "# 定义需要保留和删除的列\n",
    "# =============================================\n",
    "must_keep_cols = [\n",
    "    # \"period_year\",  # 移除！会导致时间外推问题（验证集有训练集没见过的年份）\n",
    "    \"period_month\",  # 月份可以保留（1-12 循环）\n",
    "    \"credit_score\", \"original_loan_to_value_ltv\",\n",
    "    \"original_debt_to_income_dti_ratio\", \"current_interest_rate\",\n",
    "    \"loan_age_years\", \"interest_rate_diff\"\n",
    "]\n",
    "\n",
    "# 这些列是潜在的数据泄漏或不适合作为特征\n",
    "leakage_cols = [\n",
    "    \"loan_identifier\",  # ID 列，划分后需要删除\n",
    "    \"first_payment_date\", \"maturity_date\",\n",
    "    \"loan_age\", \"remaining_months_to_legal_maturity\",\n",
    "    \"current_loan_delinquency_status\", \"payment_history\",  # ⚠️ 直接泄漏！\n",
    "    \"loan_to_value_ratio_bucket\", \"credit_score_bucket\",\n",
    "    \"high_dti_flag\", \"loan_size_bucket\", \"interest_rate_bucket\",\n",
    "    \"seasonality_flag\",\n",
    "    \"period_year\",  # 时间外推问题\n",
    "    # ⚠️ 新增可疑泄漏特征\n",
    "    \"recent_delinquency_flag\",  # 直接泄漏！这个特征可能基于目标变量计算\n",
    "    \"distressed_principal_balance_flag\",  # 可能泄漏\n",
    "    \"interest_rate_diff\",  # 如果是当前利率与原始利率的差，可能OK；但需要确认\n",
    "]\n",
    "\n",
    "# =============================================\n",
    "# 数据清洗函数\n",
    "# =============================================\n",
    "def clean_dataset(df, name, drop_leakage=True):\n",
    "    \"\"\"对单个数据集进行基本清洗\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 删除潜在泄漏列（但保留 loan_identifier 用于后续检查）\n",
    "    if drop_leakage:\n",
    "        cols_to_drop = [col for col in leakage_cols if col in df.columns and col != 'loan_identifier']\n",
    "        df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "    \n",
    "    # 转换数值类型\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object and col not in [target_col, 'loan_identifier', 'period']:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"{name} 清洗后: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# 对三个数据集分别清洗\n",
    "df_train_clean = clean_dataset(df_train, \"训练集\")\n",
    "df_val_clean = clean_dataset(df_val, \"验证集\")\n",
    "df_test_clean = clean_dataset(df_test, \"测试集\")\n",
    "\n",
    "# =============================================\n",
    "# 基于训练集确定要删除的列\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"基于训练集确定特征选择\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. 高缺失率列（基于训练集）\n",
    "missing_rate = df_train_clean.isnull().mean()\n",
    "high_missing_cols = missing_rate[missing_rate > 0.4].index.tolist()\n",
    "high_missing_cols = [col for col in high_missing_cols if col not in must_keep_cols + [target_col, 'loan_identifier', 'period']]\n",
    "print(f\"高缺失率列 (>40%): {high_missing_cols}\")\n",
    "\n",
    "# 2. 低方差列（基于训练集）\n",
    "numeric_cols = [col for col in df_train_clean.select_dtypes(include=[np.number]).columns \n",
    "                if col not in [target_col, 'loan_identifier']]\n",
    "if numeric_cols:\n",
    "    selector = VarianceThreshold(threshold=0.01)\n",
    "    try:\n",
    "        selector.fit(df_train_clean[numeric_cols].fillna(0))\n",
    "        low_var_cols = [col for col, var in zip(numeric_cols, selector.variances_) \n",
    "                        if var < 0.01 and col not in must_keep_cols]\n",
    "    except:\n",
    "        low_var_cols = []\n",
    "else:\n",
    "    low_var_cols = []\n",
    "print(f\"低方差列: {low_var_cols}\")\n",
    "\n",
    "# 3. 高相关列（基于训练集）\n",
    "numeric_cols_for_corr = [col for col in df_train_clean.select_dtypes(include=[np.number]).columns \n",
    "                          if col not in [target_col, 'loan_identifier'] + high_missing_cols + low_var_cols]\n",
    "if len(numeric_cols_for_corr) > 1:\n",
    "    corr_matrix = df_train_clean[numeric_cols_for_corr].corr()\n",
    "    drop_corr = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "                if corr_matrix.columns[i] not in must_keep_cols:\n",
    "                    drop_corr.add(corr_matrix.columns[i])\n",
    "    drop_corr = list(drop_corr)\n",
    "else:\n",
    "    drop_corr = []\n",
    "print(f\"高相关列 (>0.9): {drop_corr}\")\n",
    "\n",
    "# 合并所有要删除的列\n",
    "cols_to_remove = list(set(high_missing_cols + low_var_cols + drop_corr))\n",
    "print(f\"\\n总共删除列数: {len(cols_to_remove)}\")\n",
    "\n",
    "# 对三个数据集应用相同的列删除\n",
    "for df_clean, name in [(df_train_clean, \"训练集\"), (df_val_clean, \"验证集\"), (df_test_clean, \"测试集\")]:\n",
    "    df_clean.drop(columns=[c for c in cols_to_remove if c in df_clean.columns], inplace=True, errors='ignore')\n",
    "    print(f\"{name} 删除后: {df_clean.shape}\")\n",
    "\n",
    "# =============================================\n",
    "# LabelEncoder：只用训练集 fit\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"LabelEncoder 编码（只用训练集 fit）\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 找出需要编码的列（排除 ID 和 period）\n",
    "obj_cols = [col for col in df_train_clean.select_dtypes(include=['object']).columns \n",
    "            if col not in [target_col, 'loan_identifier', 'period']]\n",
    "print(f\"需要编码的列: {obj_cols}\")\n",
    "\n",
    "label_encoders = {}\n",
    "for col in obj_cols:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # 只用训练集 fit\n",
    "    le.fit(df_train_clean[col].astype(str))\n",
    "    \n",
    "    # 处理验证集和测试集中可能出现的未知类别\n",
    "    def safe_transform(series, encoder):\n",
    "        \"\"\"安全转换，未知类别用 -1 表示\"\"\"\n",
    "        result = []\n",
    "        for val in series.astype(str):\n",
    "            if val in encoder.classes_:\n",
    "                result.append(encoder.transform([val])[0])\n",
    "            else:\n",
    "                result.append(-1)  # 未知类别\n",
    "        return result\n",
    "    \n",
    "    # 转换三个数据集\n",
    "    df_train_clean[col] = le.transform(df_train_clean[col].astype(str))\n",
    "    df_val_clean[col] = safe_transform(df_val_clean[col], le)\n",
    "    df_test_clean[col] = safe_transform(df_test_clean[col], le)\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"编码完成，共 {len(label_encoders)} 个编码器\")\n",
    "\n",
    "# =============================================\n",
    "# 缺失值填充：用训练集的统计量\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"缺失值填充（用训练集统计量）\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 计算训练集的填充值\n",
    "fill_values = {}\n",
    "for col in df_train_clean.columns:\n",
    "    if col in [target_col, 'loan_identifier', 'period']:\n",
    "        continue\n",
    "    if df_train_clean[col].dtype == 'object':\n",
    "        fill_values[col] = df_train_clean[col].mode()[0] if len(df_train_clean[col].mode()) > 0 else 'unknown'\n",
    "    else:\n",
    "        fill_values[col] = df_train_clean[col].median()\n",
    "\n",
    "# 用训练集的统计量填充三个数据集\n",
    "for df_clean, name in [(df_train_clean, \"训练集\"), (df_val_clean, \"验证集\"), (df_test_clean, \"测试集\")]:\n",
    "    for col, fill_val in fill_values.items():\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = df_clean[col].fillna(fill_val)\n",
    "    missing_count = df_clean.isnull().sum().sum()\n",
    "    print(f\"{name} 填充后缺失值: {missing_count}\")\n",
    "\n",
    "# =============================================\n",
    "# 删除 loan_identifier 和 period（不作为特征）\n",
    "# =============================================\n",
    "for df_clean in [df_train_clean, df_val_clean, df_test_clean]:\n",
    "    df_clean.drop(columns=['loan_identifier', 'period'], inplace=True, errors='ignore')\n",
    "\n",
    "# =============================================\n",
    "# 最终数据集信息\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"最终数据集\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"训练集: {df_train_clean.shape}\")\n",
    "print(f\"验证集: {df_val_clean.shape}\")\n",
    "print(f\"测试集: {df_test_clean.shape}\")\n",
    "print(f\"\\n特征列: {[c for c in df_train_clean.columns if c != target_col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "特征矩阵和目标变量\n",
      "==================================================\n",
      "X_train: (28115, 24), y_train: (28115,)\n",
      "X_val: (3756, 24), y_val: (3756,)\n",
      "X_test: (8066, 24), y_test: (8066,)\n",
      "\n",
      "==================================================\n",
      "样本权重计算\n",
      "==================================================\n",
      "类别 0 (正常) 数量: 14020, 权重: 1.0027\n",
      "类别 1 (违约) 数量: 14095, 权重: 0.9973\n",
      "\n",
      "样本权重分配完成\n",
      "训练集样本权重范围: [0.9973, 1.0027]\n",
      "\n",
      "特征类型:\n",
      "分类特征 (9): ['period_month', 'amortization_type', 'loan_purpose', 'channel', 'property_type', 'number_of_units', 'occupancy_status', 'first_time_homebuyer_indicator', 'distressed_principal_balance_flag']\n",
      "连续特征 (15): ['seller_name', 'property_state', 'msa', 'original_loan_term', 'original_interest_rate', 'original_upb', 'credit_score', 'original_loan_to_value_ltv', 'original_debt_to_income_dti_ratio', 'mortgage_insurance_percentage_mi_percent', 'current_interest_rate', 'current_actual_upb', 'loan_age_years', 'interest_rate_diff', 'recent_delinquency_flag']\n",
      "\n",
      "分类特征类别检查:\n",
      "  ✓ period_month: OK\n",
      "  ✓ amortization_type: OK\n",
      "  ✓ loan_purpose: OK\n",
      "  ✓ channel: OK\n",
      "  ✓ property_type: OK\n",
      "  ✓ number_of_units: OK\n",
      "  ✓ occupancy_status: OK\n",
      "  ✓ first_time_homebuyer_indicator: OK\n",
      "  ✓ distressed_principal_balance_flag: OK\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 3: 准备特征矩阵和目标变量\n",
    "# =============================================\n",
    "import numpy as np\n",
    "\n",
    "target_col = \"delinquency_30d_label\"\n",
    "\n",
    "# =============================================\n",
    "# 准备 X 和 y\n",
    "# =============================================\n",
    "feature_cols = [c for c in df_train_clean.columns if c != target_col]\n",
    "\n",
    "X_train = df_train_clean[feature_cols].values\n",
    "y_train = df_train_clean[target_col].astype(int).values\n",
    "\n",
    "X_val = df_val_clean[feature_cols].values\n",
    "y_val = df_val_clean[target_col].astype(int).values\n",
    "\n",
    "X_test = df_test_clean[feature_cols].values\n",
    "y_test = df_test_clean[target_col].astype(int).values\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"特征矩阵和目标变量\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# =============================================\n",
    "# 计算样本权重（基于训练集类别分布）\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"样本权重计算\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "class_counts = np.bincount(y_train)\n",
    "w0 = class_counts.sum() / (2.0 * class_counts[0]) if class_counts[0] > 0 else 1.0\n",
    "w1 = class_counts.sum() / (2.0 * class_counts[1]) if class_counts[1] > 0 else 1.0\n",
    "\n",
    "print(f\"类别 0 (正常) 数量: {class_counts[0]}, 权重: {w0:.4f}\")\n",
    "print(f\"类别 1 (违约) 数量: {class_counts[1]}, 权重: {w1:.4f}\")\n",
    "\n",
    "# 为训练集分配样本权重\n",
    "sw_train = np.where(y_train == 1, w1, w0).astype(float)\n",
    "\n",
    "print(f\"\\n样本权重分配完成\")\n",
    "print(f\"训练集样本权重范围: [{sw_train.min():.4f}, {sw_train.max():.4f}]\")\n",
    "\n",
    "# =============================================\n",
    "# 保存特征列名（用于后续分析）\n",
    "# =============================================\n",
    "# 明确指定分类特征（这些特征的类别在训练集和验证/测试集中应该一致）\n",
    "# 注意：不要把 period_year 等时间相关特征作为分类特征！\n",
    "explicit_cat_cols = [\n",
    "    'amortization_type', 'loan_purpose', 'channel', 'property_type',\n",
    "    'occupancy_status', 'first_time_homebuyer_indicator',\n",
    "    'number_of_units', 'distressed_principal_balance_flag',\n",
    "    'period_month'  # 月份 1-12，在所有数据集中都有\n",
    "]\n",
    "\n",
    "# 识别分类特征和连续特征\n",
    "cat_cols = [col for col in feature_cols if col in explicit_cat_cols]\n",
    "cont_cols = [col for col in feature_cols if col not in cat_cols]\n",
    "\n",
    "print(f\"\\n特征类型:\")\n",
    "print(f\"分类特征 ({len(cat_cols)}): {cat_cols}\")\n",
    "print(f\"连续特征 ({len(cont_cols)}): {cont_cols}\")\n",
    "\n",
    "# 检查分类特征的类别是否在训练集中都出现过\n",
    "print(\"\\n分类特征类别检查:\")\n",
    "for col in cat_cols:\n",
    "    train_cats = set(df_train_clean[col].unique())\n",
    "    val_cats = set(df_val_clean[col].unique())\n",
    "    test_cats = set(df_test_clean[col].unique()) if len(df_test_clean) > 0 else set()\n",
    "    \n",
    "    val_new = val_cats - train_cats\n",
    "    test_new = test_cats - train_cats\n",
    "    \n",
    "    if val_new or test_new:\n",
    "        print(f\"  ⚠️ {col}: 验证集新类别={val_new}, 测试集新类别={test_new}\")\n",
    "    else:\n",
    "        print(f\"  ✓ {col}: OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAM terms 构建完成\n",
      "\n",
      "==================================================\n",
      "超参数搜索\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam= 10 -> val_log_loss=0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam= 20 -> val_log_loss=0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam= 40 -> val_log_loss=0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam= 80 -> val_log_loss=0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam=120 -> val_log_loss=0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam=160 -> val_log_loss=0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam=240 -> val_log_loss=0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lam=320 -> val_log_loss=0.0217\n",
      "  lam=480 -> val_log_loss=0.0217\n",
      "\n",
      "最佳 lambda: 480, 最佳验证集 log_loss: 0.0217\n",
      "\n",
      "==================================================\n",
      "概率校准\n",
      "==================================================\n",
      "Isotonic Regression 校准完成\n",
      "\n",
      "==================================================\n",
      "测试集评估\n",
      "==================================================\n",
      "指标              原始概率         校准后概率       \n",
      "----------------------------------------\n",
      "AUC-ROC         0.9972       0.9971      \n",
      "Brier Score     0.0029       0.0028      \n",
      "Log Loss        0.0189       0.0184      \n",
      "\n",
      "最优阈值: 0.9362\n",
      "最优 F1 Score: 0.9972\n",
      "\n",
      "分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          正常       1.00      0.99      1.00      3989\n",
      "          违约       0.99      1.00      1.00      4077\n",
      "\n",
      "    accuracy                           1.00      8066\n",
      "   macro avg       1.00      1.00      1.00      8066\n",
      "weighted avg       1.00      1.00      1.00      8066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: overflow encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n",
      "/Users/mingzhoujin/Library/Python/3.9/lib/python/site-packages/scipy/linalg/_basic.py:1449: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = (u @ vh[:rank]).conj().T\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Cell 4: LogisticGAM 模型训练\n",
    "# =============================================\n",
    "from pygam import LogisticGAM, s, f\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report, log_loss, brier_score_loss\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import numpy as np\n",
    "\n",
    "# =============================================\n",
    "# 构建 GAM terms\n",
    "# =============================================\n",
    "def build_gam_terms(feature_cols, cat_cols):\n",
    "    \"\"\"根据特征类型构建 GAM terms\"\"\"\n",
    "    terms = None\n",
    "    for i, col in enumerate(feature_cols):\n",
    "        if col in cat_cols:\n",
    "            t = f(i)  # 分类特征用 factor term\n",
    "        else:\n",
    "            t = s(i, n_splines=8, spline_order=3)  # 连续特征用 spline term\n",
    "        terms = t if terms is None else terms + t\n",
    "    return terms\n",
    "\n",
    "terms = build_gam_terms(feature_cols, cat_cols)\n",
    "print(\"GAM terms 构建完成\")\n",
    "\n",
    "# =============================================\n",
    "# 超参数搜索（使用验证集）\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"超参数搜索\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_lam, best_score, best_model = None, np.inf, None\n",
    "lam_values = [10, 20, 40, 80, 120, 160, 240, 320, 480]\n",
    "\n",
    "for lam_val in lam_values:\n",
    "    try:\n",
    "        model = LogisticGAM(terms, lam=lam_val).fit(X_train, y_train, weights=sw_train)\n",
    "        proba = np.clip(model.predict_proba(X_val), 1e-6, 1-1e-6)\n",
    "        loss = log_loss(y_val, proba)\n",
    "        print(f\"  lam={lam_val:3d} -> val_log_loss={loss:.4f}\")\n",
    "        \n",
    "        if loss < best_score:\n",
    "            best_score = loss\n",
    "            best_lam = lam_val\n",
    "            best_model = model\n",
    "    except Exception as e:\n",
    "        print(f\"  lam={lam_val:3d} -> 训练失败: {e}\")\n",
    "\n",
    "print(f\"\\n最佳 lambda: {best_lam}, 最佳验证集 log_loss: {best_score:.4f}\")\n",
    "\n",
    "# 检查是否找到了有效的模型\n",
    "if best_model is None:\n",
    "    raise ValueError(\"所有 lambda 值都训练失败！请检查数据和特征。\")\n",
    "\n",
    "# =============================================\n",
    "# 概率校准（Isotonic Regression）\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"概率校准\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 用验证集进行概率校准\n",
    "val_proba_raw = np.clip(best_model.predict_proba(X_val), 1e-6, 1-1e-6)\n",
    "iso_reg = IsotonicRegression(out_of_bounds='clip')\n",
    "iso_reg.fit(val_proba_raw, y_val)\n",
    "\n",
    "print(\"Isotonic Regression 校准完成\")\n",
    "\n",
    "# =============================================\n",
    "# 在测试集上评估\n",
    "# =============================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"测试集评估\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 原始概率\n",
    "test_proba_raw = np.clip(best_model.predict_proba(X_test), 1e-6, 1-1e-6)\n",
    "\n",
    "# 校准后概率\n",
    "test_proba_cal = np.clip(iso_reg.predict(test_proba_raw), 1e-6, 1-1e-6)\n",
    "\n",
    "# 评估指标\n",
    "auc_raw = roc_auc_score(y_test, test_proba_raw)\n",
    "auc_cal = roc_auc_score(y_test, test_proba_cal)\n",
    "\n",
    "brier_raw = brier_score_loss(y_test, test_proba_raw)\n",
    "brier_cal = brier_score_loss(y_test, test_proba_cal)\n",
    "\n",
    "logloss_raw = log_loss(y_test, test_proba_raw)\n",
    "logloss_cal = log_loss(y_test, test_proba_cal)\n",
    "\n",
    "print(f\"{'指标':<15} {'原始概率':<12} {'校准后概率':<12}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'AUC-ROC':<15} {auc_raw:<12.4f} {auc_cal:<12.4f}\")\n",
    "print(f\"{'Brier Score':<15} {brier_raw:<12.4f} {brier_cal:<12.4f}\")\n",
    "print(f\"{'Log Loss':<15} {logloss_raw:<12.4f} {logloss_cal:<12.4f}\")\n",
    "\n",
    "# 使用最优阈值计算 F1\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, test_proba_cal)\n",
    "f1_scores = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_f1 = np.max(f1_scores)\n",
    "\n",
    "print(f\"\\n最优阈值: {best_threshold:.4f}\")\n",
    "print(f\"最优 F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# 分类报告\n",
    "y_pred = (test_proba_cal >= best_threshold).astype(int)\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['正常', '违约']))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
